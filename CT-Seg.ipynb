{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1100,"status":"ok","timestamp":1603168231223,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"},"user_tz":-210},"id":"jEQGOH8S8yOn"},"outputs":[],"source":["\n","class Config:\n","    \n","    def __init__(self):\n","        #network configure\n","        self.InputCh=3\n","        self.ScaleRatio = 2\n","        self.ConvSize = 3\n","        self.pad = 1#(self.ConvSize - 1) / 2 \n","        self.MaxLv = 5\n","        self.ChNum = [self.InputCh,64]\n","        for i in range(self.MaxLv-1):\n","            self.ChNum.append(self.ChNum[-1]*2)\n","        #data configure\n","        self.pascal = \"/content/drive/My Drive/CT/CT1/\"\n","        self.bsds = \"../BSR/BSDS500/data/images/\"\n","        #self.imagelist = \"ImageSets/Segmentation/train.txt\"\n","        self.BatchSize = 6\n","        self.Shuffle = True\n","        self.LoadThread = 4\n","        self.inputsize = [224,224]\n","        #partition configure\n","        self.K = 64\n","        #training configure\n","        self.init_lr = 0.05\n","        self.lr_decay = 0.1\n","        self.lr_decay_iter = 1000\n","        self.max_iter = 50000\n","        self.cuda_dev = 0 \n","        self.cuda_dev_list = \"0,1\"\n","        self.check_iter = 1000\n","        #Ncuts Loss configure\n","        self.radius = 4\n","        self.sigmaI = 10\n","        self.sigmaX = 4\n","        #testing configure\n","        self.model_tested = \"./checkpoint_8_23_13_0_epoch_2000\"\n","        #color library\n","        self.color_lib = []\n","        for r in range(0,256,128):\n","            for g in range(0,256,128):\n","                for b in range(0,256,128):\n","                    self.color_lib.append((r,g,b))\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":27623,"status":"ok","timestamp":1603168223679,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"},"user_tz":-210},"id":"QKR3-PFO9i8c","outputId":"80789b73-154f-4e35-cd9e-46b4dc480a6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":988,"status":"ok","timestamp":1603168295382,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"},"user_tz":-210},"id":"NosKgJP2-TUY"},"outputs":[],"source":["from PIL import Image\n","import PIL\n","import torch\n","import torch.utils.data as Data\n","import os\n","import glob\n","import numpy as np\n","import pdb\n","import math\n","#import cupy as cp\n","#PIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n","config = Config()\n","\n","class DataLoader():\n","    #initialization\n","    #datapath : the data folder of bsds500\n","    #mode : train/test/val\n","    def __init__(self, datapath,mode):\n","        #image container\n","        self.path = \"/content/drive/My Drive/CT/CT1/\"\n","        self.Imgpath = os.listdir(self.path)\n","        self.raw_data = []\n","        self.mode = mode\n","        print(self.Imgpath)\n","        #navigate to the image directory\n","        #images_path = os.path.join(datapath,'images')\n","        train_image_path = os.path.join(datapath,mode)\n","        file_list = []\n","        if(mode != \"train\"):\n","            train_image_regex = os.path.join(train_image_path, '*.jpg')\n","            file_list = glob.glob(train_image_regex)\n","        #find all the images\n","        else:\n","            for i in range (len(self.Imgpath)):\n","              file_list.append(self.path + self.Imgpath[i])    \n","        #load the images\n","        for file_name in file_list:\n","            image = Image.open(file_name)\n","            if image.mode != \"RGB\":\n","              image = image.convert(\"RGB\")\n","            self.raw_data.append(np.array(image.resize((config.inputsize[0],config.inputsize[1]),Image.BILINEAR)))\n","        #resize and align\n","        self.scale()\n","        #normalize\n","        self.transfer()\n","        \n","        #calculate weights by 2\n","        if(mode == \"train\"):\n","            self.dataset = self.get_dataset(self.raw_data, self.raw_data.shape,75)\n","        else:\n","            self.dataset = self.get_dataset(self.raw_data, self.raw_data.shape,75)\n","    \n","    def scale(self):\n","        for i in range(len(self.raw_data)):\n","            image = self.raw_data[i]\n","            self.raw_data[i] = np.stack((image[:,:,0],image[:,:,1],image[:,:,2]),axis = 0)\n","        self.raw_data = np.stack(self.raw_data,axis = 0)\n","\n","    def transfer(self):\n","        #just for RGB 8-bit color\n","        self.raw_data = self.raw_data.astype(np.float)\n","        #for i in range(self.raw_data.shape[0]):\n","        #    Image.fromarray(self.raw_data[i].swapaxes(0,-1).astype(np.uint8)).save(\"./reconstruction/input_\"+str(i)+\".jpg\")\n","\n","    def torch_loader(self):\n","        return Data.DataLoader(\n","                                self.dataset,\n","                                batch_size = config.BatchSize,\n","                                shuffle = config.Shuffle,\n","                                num_workers = config.LoadThread,\n","                                pin_memory = True,\n","                            )\n","\n","    def cal_weight(self,raw_data,shape):\n","        #According to the weight formula, when Euclidean distance \u003c r,the weight is 0, so reduce the dissim matrix size to radius-1 to save time and space.\n","        print(\"calculating weights.\")\n","\n","        dissim = cp.zeros((shape[0],shape[1],shape[2],shape[3],(config.radius-1)*2+1,(config.radius-1)*2+1))\n","        data = cp.asarray(raw_data)\n","        padded_data = cp.pad(data,((0,0),(0,0),(config.radius-1,config.radius-1),(config.radius-1,config.radius-1)),'constant')\n","        for m in range(2*(config.radius-1)+1):\n","            for n in range(2*(config.radius-1)+1):\n","                dissim[:,:,:,:,m,n] = data-padded_data[:,:,m:shape[2]+m,n:shape[3]+n]\n","        #for i in range(dissim.shape[0]):\n","        #dissim = -cp.power(dissim,2).sum(1,keepdims = True)/config.sigmaI/config.sigmaI\n","        temp_dissim = cp.exp(-cp.power(dissim,2).sum(1,keepdims = True)/config.sigmaI**2)\n","        dist = cp.zeros((2*(config.radius-1)+1,2*(config.radius-1)+1))\n","        for m in range(1-config.radius,config.radius):\n","            for n in range(1-config.radius,config.radius):\n","                if m**2+n**2\u003cconfig.radius**2:\n","                    dist[m+config.radius-1,n+config.radius-1] = cp.exp(-(m**2+n**2)/config.sigmaX**2)\n","        #for m in range(0,config.radius-1):\n","        #    temp_dissim[:,:,m,:,0:config.radius-1-m,:]=0.0\n","        #    temp_dissim[:,:,-1-m,:,m-config.radius+1:-1,:]=0.0\n","        #    temp_dissim[:,:,:,m,:,0:config.radius-1-m]=0.0\n","        #    temp_dissim[:,:,:,-1-m,:,m-config.radius+1:-1]=0.0\n","        print(\"weight calculated.\")\n","        res = cp.multiply(temp_dissim,dist)\n","        #for m in range(50,70):\n","\n","        #    print(m)\n","        #    for n in range(50,70):\n","        #        print(dissim[5,0,m,n])\n","        #print(dist)\n","        return res\n","\n","    def get_dataset(self,raw_data,shape,batch_size):\n","        dataset = []\n","        for batch_id in range(0,shape[0],batch_size):\n","            print(batch_id)\n","            batch = raw_data[batch_id:min(shape[0],batch_id+batch_size)]\n","            if(self.mode == \"train\"):\n","                tmp_weight = self.cal_weight(batch,batch.shape)\n","                weight = cp.asnumpy(tmp_weight)\n","                dataset.append(Data.TensorDataset(torch.from_numpy(batch/256).float(),torch.from_numpy(weight).float()))\n","                del tmp_weight\n","            else:\n","                dataset.append(Data.TensorDataset(torch.from_numpy(batch/256).float()))\n","        cp.get_default_memory_pool().free_all_blocks()\n","        return Data.ConcatDataset(dataset)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1302,"status":"ok","timestamp":1603168303144,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"},"user_tz":-210},"id":"FHkQaqoQ-c3J"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as functional\n","import pdb\n","config = Config()\n","\n","class WNet(torch.nn.Module):\n","    def __init__(self):\n","        super(WNet, self).__init__()\n","        self.feature1 = []\n","        self.feature2 = []\n","        bias = True\n","        #U-Net1\n","        #module1\n","        self.module = []\n","        self.maxpool1 = []\n","        self.uconv1 = []\n","        self.module.append(\n","            self.add_conv_stage(config.ChNum[0],config.ChNum[1],config.ConvSize,padding=config.pad,seperable=False)   \n","        )\n","        \n","        #module2-5\n","        for i in range(2,config.MaxLv+1):\n","            self.module.append(self.add_conv_stage(config.ChNum[i-1],config.ChNum[i],config.ConvSize,padding=config.pad))\n","            \n","        #module6-8\n","        for i in range(config.MaxLv-1,1,-1):\n","            self.module.append(self.add_conv_stage(2*config.ChNum[i],config.ChNum[i],config.ConvSize,padding=config.pad))\n","        #module9\n","        self.module.append(\n","            self.add_conv_stage(2*config.ChNum[1],config.ChNum[1],config.ConvSize,padding=config.pad,seperable=False)\n","        )\n","        #module1-4\n","        for i in range(config.MaxLv-1):\n","            self.maxpool1.append(nn.MaxPool2d(config.ScaleRatio))\n","        #module5-8\n","        for i in range(config.MaxLv,1,-1):\n","            self.uconv1.append(nn.ConvTranspose2d(config.ChNum[i],config.ChNum[i-1],config.ScaleRatio,config.ScaleRatio,bias = True))\n","        self.predconv = nn.Conv2d(config.ChNum[1],config.K,1,bias = bias)\n","        self.pad = nn.ConstantPad2d(config.radius-1,0)\n","        self.softmax = nn.Softmax2d()\n","        self.module = torch.nn.ModuleList(self.module)\n","        self.maxpool1 = torch.nn.ModuleList(self.maxpool1)\n","        self.uconv1 = torch.nn.ModuleList(self.uconv1)\n","        #self.loss = NcutsLoss()\n","    def add_conv_stage(self,dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, seperable=True):\n","        if seperable:\n","            return nn.Sequential(\n","                nn.Conv2d(dim_in,dim_out,1,bias = bias),\n","                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,groups = dim_out,bias = bias),\n","                nn.ReLU(),\n","                nn.BatchNorm2d(dim_out),\n","                nn.Conv2d(dim_out,dim_out,1,bias = bias),\n","                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,groups = dim_out,bias = bias),\n","                nn.ReLU(),\n","                nn.BatchNorm2d(dim_out),\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.Conv2d(dim_in,dim_out,kernel_size,padding = padding,bias = bias),\n","                nn.ReLU(),\n","                nn.BatchNorm2d(dim_out),\n","                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,bias = bias),\n","                nn.ReLU(),\n","                nn.BatchNorm2d(dim_out),\n","            )\n","    def forward(self,x):\n","        self.feature1 = [x]\n","        #U-Net1\n","        self.feature1.append(self.module[0](x))\n","        for i in range(1,config.MaxLv):\n","            tempf = self.maxpool1[i-1](self.feature1[-1])\n","            self.feature1.append(self.module[i](tempf))\n","        for i in range(config.MaxLv,2*config.MaxLv-2):\n","            tempf = self.uconv1[i-config.MaxLv](self.feature1[-1])\n","            tempf = torch.cat((self.feature1[2*config.MaxLv-i-1],tempf),dim=1)\n","            self.feature1.append(self.module[i](tempf))\n","        tempf = self.uconv1[-1](self.feature1[-1])\n","        tempf = torch.cat((self.feature1[1],tempf),dim=1)\n","        tempf = self.module[-1](tempf)\n","        tempf = self.predconv(tempf)\n","        self.feature2 = [self.softmax(tempf)]\n","        return [self.feature2[0],self.pad(self.feature2[0])]\n","        #self.feature2.append(self.loss(self.feature2[0],self.feature2[1],w,sw))\n","        #U-Net2\n","        \n","        '''tempf = self.conv2[0](self.feature2[-1])\n","        tempf = self.ReLU2[0](tempf)\n","        tempf = self.bn2[0](tempf)\n","        tempf = self.conv2[1](tempf)\n","        tempf = self.ReLU2[1](tempf)\n","        self.feature2.append(self.bn2[1](tempf))\n","\n","        for i in range(1,config.MaxLv):\n","            tempf = self.maxpool2[i-1](self.feature2[-1])\n","            tempf = self.conv2[4*i-2](tempf)\n","            tempf = self.conv2[4*i-1](tempf)\n","            tempf = self.ReLU2[2*i](tempf)\n","            tempf = self.bn2[2*i](tempf)\n","            tempf = self.conv2[4*i](tempf)\n","            tempf = self.conv2[4*i+1](tempf)\n","            tempf = self.ReLU2[2*i+1](tempf)\n","            \n","            self.feature2.append(self.bn2[2*i+1](tempf))\n","        for i in range(config.MaxLv,2*config.MaxLv-2):\n","            tempf = self.uconv2[i-config.MaxLv](self.feature2[-1])\n","            tempf = torch.cat((self.feature2[2*config.MaxLv-i-1],tempf),dim=1)\n","            tempf = self.conv2[4*i-2](tempf)\n","            tempf = self.conv2[4*i-1](tempf)\n","            tempf = self.ReLU2[2*i](tempf)\n","            tempf = self.bn2[2*i](tempf)\n","            tempf = self.conv2[4*i](tempf)\n","            tempf = self.conv2[4*i+1](tempf)\n","            tempf = self.ReLU2[2*i+1](tempf)\n","            tempf = self.bn2[2*i+1](tempf)            \n","            self.feature2.append(tempf)\n","        tempf = self.uconv2[config.MaxLv-2](self.feature2[-1])\n","        tempf = torch.cat((self.feature2[1],tempf),dim=1)\n","        tempf = self.conv2[-2](tempf)\n","        tempf = self.ReLU2[4*config.MaxLv-4](tempf)\n","        tempf = self.bn2[4*config.MaxLv-4](tempf)\n","        tempf = self.conv2[-1](tempf)\n","        tempf = self.ReLU2[4*config.MaxLv-3](tempf)\n","        tempf = self.bn2[4*config.MaxLv-3](tempf)            \n","        self.feature2.append(tempf)\n","        tempf = self.reconsconv(self.feature2[-1])\n","        tempf = self.ReLU2[-1](tempf)\n","        self.feature2[-1] = self.bn2[-1](tempf)\n","        '''\n","\n","\n","\n","config = Config()\n","def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n","  if useBN:\n","    return nn.Sequential(\n","      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","      nn.BatchNorm2d(dim_out),\n","      nn.LeakyReLU(0.1),\n","      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","      nn.BatchNorm2d(dim_out),\n","      nn.LeakyReLU(0.1)\n","    )\n","  else:\n","    return nn.Sequential(\n","      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","      nn.ReLU(),\n","      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","      nn.ReLU()\n","    )\n","\n","def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n","  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n","  torch.cat(conv, in_fine)\n","\n","  return nn.Sequential(\n","    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n","  )\n","  upsample(in_coarse)\n","\n","def upsample(ch_coarse, ch_fine):\n","  return nn.Sequential(\n","    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n","    nn.ReLU()\n","  )\n","\n","class Net(nn.Module):\n","  def __init__(self, useBN=False):\n","    super(Net, self).__init__()\n","\n","    self.conv1   = add_conv_stage(config.InputCh, 32, useBN=useBN)\n","    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n","    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n","    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n","    self.conv5   = add_conv_stage(256, 512, useBN=useBN)\n","\n","    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n","    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n","    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n","    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n","\n","    self.conv0  = nn.Sequential(\n","        nn.Conv2d(32, config.K, 3, 1, 1),\n","        nn.Sigmoid(),\n","        nn.Softmax2d()\n","    )\n","    self.pad = nn.ConstantPad2d(config.radius-1,0)\n","    self.max_pool = nn.MaxPool2d(2)\n","\n","    self.upsample54 = upsample(512, 256)\n","    self.upsample43 = upsample(256, 128)\n","    self.upsample32 = upsample(128,  64)\n","    self.upsample21 = upsample(64 ,  32)\n","    ## weight initialization\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","        if m.bias is not None:\n","          m.bias.data.zero_()\n","    #self.Kconst = torch.tensor(config.K).float()\n","    #self.cropped_seg = torch.zeros(config.BatchSize,config.K,config.inputsize[0],config.inputsize[1],(config.radius-1)*2+1,(config.radius-1)*2+1)\n","    #self.loss = NCutsLoss()\n","\n","\n","  def forward(self, x):#, weight):\n","    #sw = weight.sum(-1).sum(-1)\n","    conv1_out = self.conv1(x)\n","    #return self.upsample21(conv1_out)\n","    conv2_out = self.conv2(self.max_pool(conv1_out))\n","    conv3_out = self.conv3(self.max_pool(conv2_out))\n","    conv4_out = self.conv4(self.max_pool(conv3_out))\n","    conv5_out = self.conv5(self.max_pool(conv4_out))\n","\n","    conv5m_out = torch.cat((self.upsample54(conv5_out), conv4_out), 1)\n","    conv4m_out = self.conv4m(conv5m_out)\n","\n","    conv4m_out_ = torch.cat((self.upsample43(conv4m_out), conv3_out), 1)\n","    conv3m_out = self.conv3m(conv4m_out_)\n","\n","    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n","    conv2m_out = self.conv2m(conv3m_out_)\n","\n","    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n","    conv1m_out = self.conv1m(conv2m_out_)\n","\n","    conv0_out = self.conv0(conv1m_out)\n","    padded_seg = self.pad(conv0_out)\n","    '''for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","        for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","            self.cropped_seg[:,:,:,:,m,n]=padded_seg[:,:,m:m+conv0_out.size()[2],n:n+conv0_out.size()[3]].clone()\n","    multi1 = self.cropped_seg.mul(weight)\n","    multi2 = multi1.view(multi1.shape[0],multi1.shape[1],multi1.shape[2],multi1.shape[3],-1).sum(-1).mul(conv0_out)\n","    multi3 = sum_weight.mul(conv0_out)\n","    assocA = multi2.view(multi2.shape[0],multi2.shape[1],-1).sum(-1)\n","    assocV = multi3.view(multi3.shape[0],multi3.shape[1],-1).sum(-1)\n","    assoc = assocA.div(assocV).sum(-1)\n","    loss = self.Kconst - assoc'''\n","    #loss = self.loss(conv0_out, padded_seg, weight, sw)\n","    return [conv0_out,padded_seg]\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1010,"status":"ok","timestamp":1603168310844,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"},"user_tz":-210},"id":"rpewACKC-neT"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as func\n","from torch.autograd import Function\n","import time\n","import pdb\n","import subprocess\n","import numpy as np\n","\n","config = Config()\n","\n","class NCutsLoss(nn.Module):\n","    def __init__(self):\n","        super(NCutsLoss,self).__init__()\n","        self.gpu_list = []\n","        '''\n","        for i in range(torch.cuda.device_count()):\n","            self.gpu_list.append(torch.cuda.device(i))\n","# the ratio of the free space among all gpus\n","        self.gpu_room_list = []\n","        self.gpu_room_update()\n","        '''\n","    '''def gpu_room_update(self):\n","        self.gpu_room_list = []\n","        free_memory = get_gpu_memory_map()\n","        total_free = 0\n","        count_ratio = 0.0\n","        for _, value in free_memory.items():\n","            total_free+=value\n","        for dev in self.gpu_list:\n","            ratio = float(free_memory[dev])/total_free\n","            self.gpu_room_list.append(ratio)\n","            count_ratio += ratio\n","        if (count_ratio - 1 \u003c 0):\n","            self.gpu_room_list[-1]+=1.0-count_ratio \n","    '''    \n","            \n","\n","    def forward(self, seg, padded_seg, weight,sum_weight):\n","        #too many values to unpack\n","        cropped_seg = []\n","        for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","            column = []\n","            for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","                column.append(padded_seg[:,:,m:m+seg.size()[2],n:n+seg.size()[3]].clone())\n","            cropped_seg.append(torch.stack(column,4))\n","        cropped_seg = torch.stack(cropped_seg,4)\n","        #for m in torch.arange(50,70,dtype=torch.long):\n","\n","        #    print(m)\n","        #    for n in torch.arange(50,70,dtype= torch.long):\n","        #        print(weight[5,0,m,n])\n","        multi1 = cropped_seg.mul(weight)\n","        multi2 = multi1.sum(-1).sum(-1).mul(seg)\n","        multi3 = sum_weight.mul(seg)\n","        #print(\"=============================================================================\")\n","        #for a in [0,1]:\n","        #    print(multi2[5,0,a*10+50:a*10+60,50:60])\n","        #    print(multi2[5,0,a*10+50:a*10+60,60:70])\n","        assocA = multi2.view(multi2.shape[0],multi2.shape[1],-1).sum(-1)\n","        assocV = multi3.view(multi3.shape[0],multi3.shape[1],-1).sum(-1)\n","        assoc = assocA.div(assocV).sum(-1)\n","        \n","        return torch.add(-assoc,config.K)\n","        \n","    '''def crop_seg(self,seg):\n","        cropped_seg = torch.zeros(seg.size()[0],seg.size()[1],seg.size()[2],seg.size()[3],(config.radius-1)*2+1,(config.radius-1)*2+1)\n","        padding_size = (config.radius,config.radius,config.radius,config.radius)\n","        padded_seg = torch.nn.functional.pad(seg,padding_size)\n","        for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","            for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n","                cropped_seg[:,:,:,:,m,n].copy_(padded_seg[:,:,m:m+seg.size()[2],n:n+seg.size()[3]])\n","        return cropped_seg\n","    \n","def get_gpu_memory_map():\n","    \"\"\"Get the current gpu usage.\n","\n","    Returns\n","    -------\n","    usage: dict\n","        Keys are device ids as integers.\n","        Values are memory free as integers in MB.\n","    \"\"\"\n","    result = subprocess.check_output(\n","        [\n","            'nvidia-smi', '--query-gpu=memory.free',\n","            '--format=csv,nounits,noheader'\n","        ], encoding='utf-8')\n","    # Convert lines into a dictionary\n","    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n","    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n","    return gpu_memory_map\n","'''        \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":54,"output_embedded_package_id":"1xMijvnEpzXQaftJWPsGUVWxsMv1YC1Q9"},"id":"u2pF-Xxa-z6n","outputId":"cb8a7568-d190-4527-89d0-912ca077532f"},"outputs":[],"source":["import torch\n","import numpy as np\n","import time\n","import os\n","\n","config = Config()\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=config.cuda_dev_list\n","if __name__ == '__main__':\n","    dataset = DataLoader(config.pascal,\"train\")\n","    dataloader = dataset.torch_loader()\n","    #model = torch.nn.DataParallel(Net(True))\n","    model = torch.nn.DataParallel(WNet())\n","    model.cuda()\n","    #model.to(device)\n","    model.train()\n","    #optimizer\n","    \n","    optimizer = torch.optim.SGD(model.parameters(),lr = config.init_lr)\n","    #reconstr = torch.nn.MSELoss().cuda(config.cuda_dev)\n","    Ncuts = NCutsLoss()\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.lr_decay_iter, gamma=config.lr_decay)\n","    \n","    for epoch in range(config.max_iter):\n","        print(\"Epoch: \"+str(epoch+1))\n","        scheduler.step()\n","        Ave_Ncuts = 0.0\n","        #Ave_Rec = 0.0\n","        t_load = 0.0\n","        t_forward = 0.0\n","        t_loss = 0.0\n","        t_backward = 0.0\n","        t_adjust = 0.0\n","        t_reset = 0.0\n","        t_inloss = 0.0\n","        for step,[x,w] in enumerate(dataloader):\n","            #NCuts Loss\n","            #tick = time.time()\n","            x = x.cuda()\n","            w = w.cuda()\n","            #for m in torch.arange(50,70,dtype=torch.long):\n","\n","            #    print(m)\n","            #    for n in torch.arange(50,70,dtype= torch.long):\n","            #        print(w[5,0,m,n])\n","            sw = w.sum(-1).sum(-1)\n","            #t_load += time.time()-tick\n","            #tick = time.time()\n","            optimizer.zero_grad()\n","            pred,pad_pred = model(x)\n","            #t_forward += time.time()-tick\n","            #pred.cuda()\n","            #tick = time.time()\n","            ncuts_loss = Ncuts(pred,pad_pred,w,sw)\n","            ncuts_loss = ncuts_loss.sum()/config.BatchSize \n","            #t_loss += time.time()-tick\n","            #tick = time.time()\n","            Ave_Ncuts = (Ave_Ncuts * step + ncuts_loss.item())/(step+1)\n","            #t_reset += time.time()-tick\n","            #tick = time.time()\n","            ncuts_loss.backward()\n","            #t_backward += time.time()-tick\n","            #tick = time.time()\n","            optimizer.step()\n","            #t_adjust += time.time()-tick\n","            #Reconstruction Loss\n","            '''pred,rec_image = model(x)\n","            rec_loss = reconstr(rec_image,x)\n","            Ave_Rec = (Ave_Rec * step + rec_loss.item())/(step+1)\n","            optimizer.zero_grad()\n","            rec_loss.backward()\n","            optimizer.step()'''\n","            torch.cuda.empty_cache()\n","        #t_total = t_load+t_reset+t_forward+t_loss+t_backward+t_adjust\n","        print(\"Ncuts loss: \"+str(Ave_Ncuts))#+\";total time: \"+str(t_total)+\";forward: \"+str(t_forward/t_total)+\";loss: \"+str(t_loss/t_total)+\";backward: \"+str(t_backward/t_total)+\";adjust: \"+str(t_adjust/t_total)+\";reset\u0026load: \"+str(t_reset/t_total)+\"\u0026\"+str(t_load/t_total)+\"loss: \"+str(t_loss)+\" / \"+str(t_inloss))\n","        #print(\"Reconstruction loss: \"+str(Ave_Rec))\n","        if (epoch+1)%500 == 0:\n","            localtime = time.localtime(time.time())\n","            checkname = './checkpoints'\n","            if not os.path.isdir(checkname):\n","                os.mkdir(checkname)\n","            checkname+='/checkpoint'\n","            for i in range(1,5):\n","                checkname+='_'+str(localtime[i])\n","            checkname += '_epoch_'+str(epoch+1)\n","            with open(checkname,'wb') as f:\n","                torch.save({\n","                    'epoch': epoch +1,\n","                    'state_dict': model.module.state_dict(),\n","                    'optimizer': optimizer.state_dict(),\n","                    'scheduler': scheduler.state_dict(),\n","                    'Ncuts': Ave_Ncuts#,\n","                    #'recon': Ave_Rec\n","                    },f)\n","            print(checkname+' saved')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3LCuylVEXsv"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTqGuxmQiXdgKFSIBNR5dm","collapsed_sections":[],"name":"CT-Seg.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}