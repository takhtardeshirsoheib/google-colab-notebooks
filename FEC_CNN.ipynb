{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FEC_CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CC6qzH4B9e30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614788197263,"user_tz":-210,"elapsed":35867,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"}},"outputId":"2c7b3f2d-29a0-424d-b953-273ac808e3ca"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KLCDi0LVlkmA","executionInfo":{"status":"ok","timestamp":1614788213702,"user_tz":-210,"elapsed":4621,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"}}},"source":["import os\r\n","import cv2\r\n","import random\r\n","import numpy as np\r\n","import pandas as pd\r\n","from tqdm import tqdm\r\n","import tensorflow as tf\r\n","import keras\r\n","from keras_preprocessing import image\r\n","from keras import preprocessing\r\n","import matplotlib.pyplot as plt\r\n","from keras.models import Sequential\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense , Activation , Dropout ,Flatten\r\n","from keras.layers.convolutional import Conv2D\r\n","from keras.layers.convolutional import MaxPooling2D\r\n","from keras.metrics import categorical_accuracy\r\n","from keras.optimizers import *\r\n","from keras.layers.normalization import BatchNormalization"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYGp4-Qck-5L","executionInfo":{"status":"ok","timestamp":1612942272435,"user_tz":-210,"elapsed":1080,"user":{"displayName":"Soheib Takhtardeshir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikDsGcdXzPRT0E9ePB2VsORotDCDzVXhRQdsL2jQ=s64","userId":"07721176589740380310"}},"outputId":"9c433ecf-1489-402f-b997-92fb9779006a"},"source":["########################################################################################################################\r\n","################################################## Parameters ##########################################################\r\n","########################################################################################################################\r\n","img_width = 224\r\n","img_height = 224\r\n","img_channel = 3\r\n","BATCH_SIZE = 8\r\n","\r\n","########################################################################################################################\r\n","################################################ Model building ########################################################\r\n","########################################################################################################################\r\n","final_model = Sequential()\r\n","\r\n","# 1 - Convolution\r\n","final_model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\r\n","final_model.add(BatchNormalization())\r\n","final_model.add(Activation('relu'))\r\n","final_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n","final_model.add(Dropout(0.25))\r\n","\r\n","# 2nd Convolution layer\r\n","final_model.add(Conv2D(128,(5,5), padding='same'))\r\n","final_model.add(BatchNormalization())\r\n","final_model.add(Activation('relu'))\r\n","final_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n","final_model.add(Dropout(0.25))\r\n","\r\n","# 3rd Convolution layer\r\n","final_model.add(Conv2D(512,(3,3), padding='same'))\r\n","final_model.add(BatchNormalization())\r\n","final_model.add(Activation('relu'))\r\n","final_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n","final_model.add(Dropout(0.25))\r\n","\r\n","\r\n","# Flattening\r\n","final_model.add(Flatten())\r\n","\r\n","# Fully connected layer 1st layer\r\n","final_model.add(Dense(256))\r\n","final_model.add(BatchNormalization())\r\n","final_model.add(Activation('relu'))\r\n","final_model.add(Dropout(0.25))\r\n","\r\n","\r\n","# Fully connected layer 2nd layer\r\n","final_model.add(Dense(512))\r\n","final_model.add(BatchNormalization())\r\n","final_model.add(Activation('relu'))\r\n","final_model.add(Dropout(0.25))\r\n","\r\n","final_model.add(Dense(7, activation='sigmoid'))\r\n","\r\n","#base_model.summary()\r\n","final_model.summary()\r\n","\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 48, 48, 64)        256       \n","_________________________________________________________________\n","activation (Activation)      (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 24, 24, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 12, 12, 512)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 18432)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               4718848   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 256)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 5,655,815\n","Trainable params: 5,652,871\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ZzQYXWs1Ysf"},"source":["address = '/home/rd/apply/MMAFEDB/'\r\n","\r\n","train_list = os.listdir(address + 'train')\r\n","test_list = os.listdir(address + 'test')\r\n","\r\n","labels_train = []\r\n","image_paths_train = []\r\n","\r\n","for i in range(len(train_list)):\r\n","  imgs_tr = os.listdir(address + 'train/'+train_list[i])\r\n","  for img in imgs_tr:\r\n","    image_paths_train.append(address + 'train/'+train_list[i] +'/'+img)\r\n","    labels_train.append(i)\r\n","\r\n","\r\n","labels_test = []\r\n","image_paths_test = []\r\n","\r\n","for i in range(len(train_list)):\r\n","  imgs_ts = os.listdir(address + 'test/'+train_list[i])\r\n","  for img in imgs_ts:\r\n","    image_paths_test.append(address + 'test/'+train_list[i] +'/'+img)\r\n","    labels_test.append(i)\r\n","\r\n","print(len(labels_test))\r\n","\r\n","training_index = list(np.linspace(0, len(labels_train)-1,len(labels_train), dtype='int'))\r\n","\r\n","print(image_paths_train[:10])\r\n","print(labels_train)\r\n","\r\n","import numpy as np\r\n","def train_generator(BATCH_SIZE):\r\n","    X = np.zeros((BATCH_SIZE, img_width, img_height, img_channel))\r\n","    Y = []\r\n","    index = 0\r\n","    random.shuffle(training_index)\r\n","    while(True):\r\n","        for i in range(BATCH_SIZE):\r\n","            img = cv2.imread(image_paths_train[training_index[index]])\r\n","            img = cv2.resize(src=img, dsize=(img_width, img_height))\r\n","            img = img/127.5 - 1\r\n","            X[i] = img\r\n","            Y.append(labels_train[training_index[index]])\r\n","            index += 1\r\n","            if (index == len(training_index)):\r\n","                index = 0\r\n","                random.shuffle(training_index)\r\n","        yield X, tf.keras.utils.to_categorical(y=Y, num_classes=7)\r\n","        X = np.zeros((BATCH_SIZE, img_width, img_height, img_channel))\r\n","        Y = []\r\n","\r\n","\r\n","def test_generator(n):\r\n","    X = np.zeros((n, img_width, img_height, img_channel))\r\n","    Y = []\r\n","    index = np.random.randint(0,17345,n,dtype='int')\r\n","    for i in range(n):\r\n","        img = cv2.imread(image_paths_test[index[i]])\r\n","        img = cv2.resize(src=img, dsize=(img_width, img_height))\r\n","        img = img/127.5 - 1\r\n","        X[i] = img\r\n","        Y.append(labels_test[index[i]])\r\n","    return X, tf.keras.utils.to_categorical(y=Y, num_classes=7)\r\n","    \r\n","        \r\n","\r\n","#x_test, y_test = test_generator()\r\n","\r\n","########################################################################################################################\r\n","##################################################### Train ############################################################\r\n","########################################################################################################################\r\n","monitor = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-3, patience=50, mode='auto', restore_best_weights=True)\r\n","final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n","hist = final_model.fit(x=train_generator(BATCH_SIZE), epochs=60, validation_data=test_generator(2300), callbacks=[monitor], steps_per_epoch=11620)\r\n"],"execution_count":null,"outputs":[]}]}